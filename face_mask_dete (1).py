# -*- coding: utf-8 -*-
"""face mask dete.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N_H0KK3z9jCns-9K9kp3dameTo6DnFgt
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#api to fetch datasets from kaggle
!kaggle datasets download -d omkargurav/face-mask-dataset

from zipfile import ZipFile
dataset = "/content/face-mask-dataset.zip"

with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print("Done extarcting dataset")

#this command lists all directories uploaded
!ls

"""finished importing the dataset
and now start building model
1. import the dependencies
2. apply label encoding
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
from sklearn.model_selection import train_test_split

files_with_mask = os.listdir('/content/data/with_mask')
print(files_with_mask[:5])
files_without_mask = os.listdir('/content/data/without_mask')
print(files_without_mask[:5])

print('Number of files with mask:', len(files_with_mask))
print('Number of files without mask:', len(files_without_mask))

#create labels for performing label encoding
with_mask_labels = [1]*3725
without_mask_labels = [0]*3828

print(with_mask_labels[:5])
print(without_mask_labels[:5])

#combining these datasets
labels = with_mask_labels + without_mask_labels

print(len(labels))
print(labels[:5])

"""displaying the images"""

img=mpimg.imread('/content/data/with_mask/with_mask_5.jpg')
imgplot = plt.imshow(img)
plt.show

"""we need to apply image processing as all images have different dimensions.
step 1: resize the images.
step 2: convert the image to numpy arrays
"""

#converting images to numpy arrays


files_with_mask_path =('/content/data/with_mask/')
data =[]
for file_img in files_with_mask:
  image = Image.open(files_with_mask_path + file_img)
  image = image.resize((128,128))
  image = image.convert('RGB')  #color all img if any black and white img comes
  image = np.array(image)
  data.append(image)


files_without_mask_path =('/content/data/without_mask/')

for file_img in files_without_mask:
  image = Image.open(files_without_mask_path + file_img)
  image = image.resize((128,128))
  image = image.convert('RGB')  #color all img if any black and white img comes
  image = np.array(image)
  data.append(image)

type(data)

len(data)

data[0]   #this shows that img are converted to arrays and 3 matrices are seen which are the red,green and blue color for them.

#converting img list and label list to numpy arrays
X = np.array(data)
Y = np.array(labels)

"""Train test split data"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=3)

print(X.shape)
print(X_train.shape)
print(X_test.shape)

#scaling the data. this is done as above color ranges from 0 to 255 and now we are chsnging the range to 0 and 1.

X_train_scaled = X_train/255
X_test_scaled = X_test/255

"""building cnn

"""

import tensorflow as tf
from tensorflow import keras

num_of_classes = 2

model = keras.Sequential()
model.add(keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(128,128,3)))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))

model.add(keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))

model.add(keras.layers.Flatten())

model.add(keras.layers.Dense(128,activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(64,activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(num_of_classes,activation='sigmoid'))

#above was the architecture for neural network and now we r compiling
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

#training the network
history = model.fit(X_train_scaled,Y_train,validation_split=0.1,epochs=10)

#model evaluation

loss,accuracy = model.evaluate(X_test_scaled,Y_test)
print(accuracy)

h = history
plt.plot(h.history['accuracy'])
plt.plot(h.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'])
plt.show()

h = history
plt.plot(h.history['loss'])
plt.plot(h.history['val_loss'])
plt.title('model accuracy')
plt.ylabel('loss')
plt.xlabel('validation loss')
plt.legend(['train','test'])
plt.show()

#predictive system

input_img_path = input('enter img path')
input_img = cv2.imread(input_img_path)
cv2_imshow(input_img)

input_img_resized = cv2.resize(input_img,(128,128))

input_img_scaled = input_img_resized/255

input_img_reshaped = np.reshape(input_img_scaled,[1,128,128,3])

input_prediction = model.predict(input_img_reshaped)
print(input_prediction)

input_pred_label = [np.argmax(input_prediction)]
print(input_pred_label)


if input_pred_label[0] ==0:
  print('person wears a mask')
else:
  print('person is not wearing mask')

import pickle

# Save the model
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

# Load the model
with open('model.pkl', 'rb') as f:
    loaded_model = pickle.load(f)

